{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ДЗ №6 - автокодировщики для идентификации аномалий"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этом ДЗ вам предстоит применить модель сврточного автокодировщика для идентификации аномалий в данных."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для этого вам потребуется создать сверточный автокодировщик, обучить его и применить к тестовым данным.\n",
    "\n",
    "Основная идея фильтрации аномалий состоит в том, что экземпляры выборки, являющиеся аномалиями, сильно отличаются от всех остальных объектов. Кроме того, их мало по сранению с размером всей выборки.\n",
    "Этот набор факторов приводит к тому, что автокодировщик, обученный на данных тренировочной выборки, будет довольно плохо восстанавливать примеры-аномалии. То есть, значения функции потерь на таких примерах ожидается нетипично высоким."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Эту ячейку следует выоплнять в окружении, в котором еще не установлены необходимые библиотеки. В подготовленном окружении эту ячейку можно пропустить.\n",
    "!pip3 install torch torchvision numpy matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "\n",
    "from typing import Tuple, List, Type, Dict, Any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Свёрточный автокодировщик (convolutional autoencoder, CAE)\n",
    "\n",
    "Данными в этой задаче будут все так же набор рукописных цифр MNIST. Однако некоторые экземпляры тестовой выборки оказываются испорченными. Ваша цель - найти эти экземпляры в предположении, что они представляют собой аномалии.\n",
    "\n",
    "Данные MNIST с дефектами нужно скачать в виде файла по <a href=\"https://www.dropbox.com/s/r7mgjn83y9ygpzq/mnist_corrupted.npz\">ссылке</a>\n",
    "\n",
    "Прежде всего следует построить и обучить свёрточный автокодировщик.\n",
    "\n",
    ">Кодирующая часть автокодировщика (encoder, кодировщик) может состоять из сверточных слоев (convolutional layers) и слоев субдискретизации (pooling layers), но может быть и сложнее. Здесь предлагается применить ваши знания относительно возможной структуры сверточных сетей. Кодировщик, будучи обученным, позволяет извлечь скрытое представление (hidden representation, embeddings) входных примеров, содержащее достаточно информации для восстановления этих примеров декодером.\n",
    "\n",
    "> Декодер (decoder) может состоять из слоев типа **transpose convolution** и операций масштабирования (upsampling), но также, как и кодировщик, может быть сложнее. Декодер должен восстанавливать примеры, руководствуюясь их векторами скрытого представления.\n",
    "\n",
    "<img src='imgs/autoencoder_1.png' />\n",
    "\n",
    "### Скрытое представление (hidden representation, compressed representation)\n",
    "\n",
    "Скрытое представление может содержать семантически насыщенную информацию о входных примерах. С использованием этих данных можно проводить фильтрацию шума в примерах, восстанавливать сами примеры, и иногда даже проводить некоторые операции в семантическом пространстве."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В предположении, что файл данных `mnist_corrupted.npz` загружен и находится в той же директории, что и этот нотбук, генераторы данных можно описать следующим образом:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DS(Dataset):\n",
    "    def __init__(self, data, transform=None):\n",
    "        self.data = data\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x = self.data[index]\n",
    "\n",
    "        if self.transform:\n",
    "            x = Image.fromarray(x.astype(np.uint8))\n",
    "            x = self.transform(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = np.load('./mnist_corrupted.npz')\n",
    "mnist_train_samples = mnist['x_train']\n",
    "mnist_test_samples = mnist['x_test']\n",
    "train_dataset = DS(mnist_train_samples, train_transforms)\n",
    "val_dataset = DS(mnist_test_samples, val_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Визуализация исходных данных\n",
    "\n",
    "Как и в любой задаче, имеет смысл визуализировать исходные данные, чтобы понимать, с чем мы имеем дело"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.random.randint(0, len(train_dataset), size=8)\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=8, figsize=(8, 2), dpi=300)\n",
    "for i, ax in enumerate(axes):\n",
    "    sample_index = indices[i]\n",
    "    sample = train_dataset[sample_index]\n",
    "    ax.imshow(np.squeeze(sample.cpu().numpy()), cmap='gray')\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "plt.tight_layout()\n",
    "fig.patch.set_facecolor('white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Свёрточный автокодировщик\n",
    "\n",
    "#### Кодировщик (Encoder)\n",
    "Кодировщик можно реализовать в подходе AlexNet или VGG: сверточные (convolutional) слои чередуются со слоями субдискретизации (pooling). Последние применяются для снижения пространственных размерностей промежуточных представлений входных примеров. Нередко после сверточной части добавляют дополнительные полносвязные слои, позволяющие еще сильнее снизить размерность скрытого представления, извлекаемого кодировщиком.\n",
    "\n",
    "Предлагаемая структура кодировщика не единственно верная. Можно реализовывать и другие.\n",
    "\n",
    "#### Декодер\n",
    "\n",
    "Декодер должен преобразовать вектор скрытого представления (тензор ранга 1) в изображение, реконструкцию входного примера. Для этого следует вектор скрытого представления перевести в ранг 2 (например, операцией `.view()`). После этого следует последовательно применять операции Transpose Convolution (`torch.nn.ConvTranspose2d`) и масштабирования (upsampling, а именно `torch.nn.functional.interpolate`). В некоторых случаях применяют `torch.nn.ConvTranspose2d` с аргументом `stride=2` или больше. Однако такое использование может привести в т.н. [\"эффекту шахматной доски\"](https://distill.pub/2016/deconv-checkerboard/). Рекомендуемым вариантом сейчас считается применение масштабирования типа билинейного или бикубического.\n",
    "\n",
    "Результатом работы декодера должно получиться изображение, по размеру совпадающее с входным примером, то есть, 28x28.\n",
    "\n",
    "Не следует забывать, что одной из целей применения автокодировщиков является снижение размерности примеров с сохранением ключевой информации. Экспериментируйте с количеством слоев и размерностью скрытого представления! Попробуйте снизить его до 2 или вообще до 1. Хорошо ли будут воспроизводиться примеры выборки?\n",
    "\n",
    "### Transpose Convolutions\n",
    "\n",
    "В этом ДЗ в декодере предлагается использовать слои типа **transposed convolutional**. Они работают практически так же, как свёрточные слои, но \"задом наперед\". Например, ядро размером 3x3 в случае свёрточной операции дает в результате одно значение. Операция **transposed convolutional**, наоборот, одно значение входного представления трансформирует в патч размером с его ядро (3x3). В PyTorch есть уже готовая реализация слоев [`nn.ConvTranspose2d`](https://pytorch.org/docs/stable/nn.html#convtranspose2d).\n",
    "\n",
    "Повторимся, альтернативой использованию **transposed convolutional layer** с аргументом `stride=2` или больше может быть применение операций изменения размера (resizing) с интерполяцией типа \"nearest neighbor\", \"bilinear\" или \"bicubic\" и применением свёрточной операции к результату."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 1:  Описать класс нейросети-автокодировщика, описываемой в этом задании."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the NN architecture\n",
    "class ConvAutoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvAutoencoder, self).__init__()\n",
    "        ## слои кодировщика ##\n",
    "        # YOUR CODE HERE\n",
    "        \n",
    "        ## слои декодера ##\n",
    "        # YOUR CODE HERE\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        ## применить операции кодировщика ##\n",
    "        \n",
    "        ## применить операции декодера ##\n",
    "        ## На всех скрытых слоях применяйте функцию активации ReLU\n",
    "        ## В случае, если данные отнормированы к диапазону [0,1], активацией последнего слоя может быть sigmoid.\n",
    "        ## Подумайте, какая может быть функция активации в других случаях. Реализуйте подходящий вариант\n",
    "                        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ConvAutoencoder()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 2: Напишите пайплайн для предобработки и аугументации данных.\n",
    "\n",
    "В `torchvision.transforms` есть готовые реализации большинства распространённых техник, если вы хотите добавить что-то своё, вы можете воспользоваться `torchvision.transforms.Lambda` или встроить аугментации на этапе подготовки данных в классе `DS`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = torchvision.transforms.Compose([\n",
    "    #YOUR CODE HERE\n",
    "    torchvision.transforms.ToTensor()])\n",
    "\n",
    "val_transforms = torchvision.transforms.Compose([\n",
    "    #YOUR CODE HERE\n",
    "    torchvision.transforms.ToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Всегда имеет смысл посмотреть, как происходит предобработка данных, и как происходит обработка данных нейросетью (если это возможно). В этом ДЗ предлагается визуализировать произвольные примеры из обучающей выборки, а также один из произвольных примеров, обработанных только что созданной (но не обученной) моделью."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 3: отобразите несколько произвольных примеров обучающей выборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## YOUR CODE HERE ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 4: отобразите один произвольный пример обучающей выборки и результат вычисления нейросети на этом примере."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_index = int(np.random.randint(0, len(train_dataset), size=1))\n",
    "example = train_dataset[example_index]\n",
    "\n",
    "## compute model output for this example;\n",
    "## Transfer the result to CPU and convrt it from tensor to numpy array\n",
    "example_transformed = None\n",
    "## YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Now plot the example and the transformed example\n",
    "## YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучение модели\n",
    "\n",
    "Теперь, когда вы реализовали модель и подготовили данные, можно приступить к непосредственному обучению модели.\n",
    "\n",
    "Костяк функции обучения написан ниже, далее вы должны будете реализовать ключевые части этого алгоритма"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model: torch.nn.Module, \n",
    "                train_dataset: torch.utils.data.Dataset,\n",
    "                val_dataset: torch.utils.data.Dataset,\n",
    "                loss_function: torch.nn.Module = torch.nn.CrossEntropyLoss(),\n",
    "                optimizer_class: Type[torch.optim.Optimizer] = torch.optim.Adam,\n",
    "                optimizer_params: Dict = {},\n",
    "                lr_scheduler_class: Any = torch.optim.lr_scheduler.ExponentialLR,\n",
    "                lr_scheduler_params: Dict = {},\n",
    "                batch_size = 64,\n",
    "                max_epochs = 100,\n",
    "                early_stopping_patience = 10\n",
    "):\n",
    "    optimizer = optimizer_class(model.parameters(), **optimizer_params)\n",
    "    lr_scheduler = lr_scheduler_class(optimizer, **lr_scheduler_params)\n",
    "    \n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, shuffle=True, batch_size=batch_size)\n",
    "    val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size)\n",
    "\n",
    "    best_val_loss = None\n",
    "    best_epoch = None\n",
    "    \n",
    "    for epoch in range(max_epochs):\n",
    "        print(f'Epoch {epoch+1} of {max_epochs}')\n",
    "        train_single_epoch(model, optimizer, loss_function, train_loader)\n",
    "        val_metrics = validate_single_epoch(model, loss_function, val_loader)\n",
    "        print(f'Validation metrics: \\n{val_metrics}')\n",
    "\n",
    "        lr_scheduler.step(val_metrics['loss'])\n",
    "        \n",
    "        if best_val_loss is None or best_val_loss > val_metrics['loss']:\n",
    "            print(f'Best model yet, saving')\n",
    "            best_val_loss = val_metrics['loss']\n",
    "            best_epoch = epoch\n",
    "#             torch.save(model, './best_model.pth')\n",
    "            \n",
    "        if epoch - best_epoch > early_stopping_patience:\n",
    "            print('Early stopping triggered')\n",
    "            return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 5:  Реализуйте функцию, производящую обучение сети на протяжении одной эпохи ( полного прохода по всей обучающей выборке ). На вход будет приходить модель, оптимизатор, функция потерь и объект типа `DataLoader`.\n",
    "> ВНИМАНИЕ!!! В задаче обучения автокодировщика нет меток-цифр. Есть только входные примеры. При итерировании по `data_loader` вы будете получать только сами примеры! Подумайте, что должно выступать в качестве целевой переменной, когда вы вычисляете функцию потерь."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_single_epoch(model: torch.nn.Module,\n",
    "                       optimizer: torch.optim.Optimizer, \n",
    "                       loss_function: torch.nn.Module, \n",
    "                       data_loader: torch.utils.data.DataLoader):\n",
    "    \n",
    "    model.train()\n",
    "    ## YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 6:  Реализуйте функцию производящую расчёт функции потерь на тестовой выборке.  На вход будет приходить модель, функция потерь и DataLoader. На выходе ожидается словарь с вида:\n",
    "```\n",
    "{\n",
    "    'loss': <среднее значение функции потерь>,\n",
    "    'accuracy': <среднее значение точности модели>\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_single_epoch(model: torch.nn.Module,\n",
    "                          loss_function: torch.nn.Module, \n",
    "                          data_loader: torch.utils.data.DataLoader):\n",
    "    \n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    \n",
    "    ## YOUR CODE HERE\n",
    "    \n",
    "    return {\n",
    "        'loss': test_loss / len(data_loader.dataset)\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если вы корректно реализовали все предыдущие шаги и ваша модель имеет достаточное количество обучаемых параметров, то в следующей ячейке должен пойти процесс обучения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 7: придумайте функцию потерь.\n",
    "\n",
    "Обратите внимание, что в предложенном скелетном коде функция потерь по умолчанию прописана неверно. Вы, скорее всего, не сможете обучить автокодировщик с этой функцией потерь. Подумайте, какая должна быть функция потерь при условии, что она должна оценивать качество воспроизведения значений в каждом отдельном пикселе изображения. Впишите в ячейке ниже правильную функцию потерь. Подумайте, можно ли использовать уже предложенную функцию потерь, и что нужно сделать с данными, чтобы с ней можно было обучить вашу модель."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model(model, \n",
    "            train_dataset=train_dataset, \n",
    "            val_dataset=val_dataset, \n",
    "            loss_function=None, \n",
    "            initial_lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проверка результатов\n",
    "\n",
    "Посмотрите, как ваш обученный автокодировщик преобразует входные примеры. В ячейке ниже приведен код для отображения произвольной пары пример-реконструкция."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = int(np.random.randint(0, len(train_dataset), size=1))\n",
    "sample = train_dataset[index][0]\n",
    "sample_np = np.squeeze(sample.detach().cpu().numpy())\n",
    "sample_ae = model(sample.view(1,1,28,28).to(device))\n",
    "sample_ae_np = np.squeeze(sample_ae.detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(4, 2), dpi=200)\n",
    "for i, ax in enumerate(axes):\n",
    "    img = sample_np if i==0 else sample_ae_np\n",
    "    ax.imshow(img, cmap='gray')\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "plt.tight_layout()\n",
    "fig.patch.set_facecolor('white')\n",
    "plt.imshow(img, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Идентификация аномалий.\n",
    "\n",
    "Идея идентификации аномалий состоит в том, чтобы разделить \"обычные\" экземпляры и \"необычные\" по значению функции потерь автокодировщика на этих примерах. Предполагается, что автокодировщик, обученный на обычных примерах не будет способен достаточно точно воспроизвести необычные примеры. То есть, значение функции потерь на необычных экземплярах будет большим. В этом ДЗ предлагается найти все экземпляры-выбросы, встречающиеся в тестовой выборке, руководствуюясь только значениями функции потерь автокодировщика. Для этого на всех объектах тестовой выборки следует вычислить функцию потерь обученного автокодировщика, и определить, какие экземпляры являются аномальными.\n",
    "\n",
    "В качестве решения всего задания следует получить список значений 0 или 1, соответствующих объектам тестовой выборки. Признак `1` означает, что этот объект является аномалией, `0` - означает, что объект обычный.\n",
    "\n",
    "Например, следующий список `[1,1,1,0,0,0,0,0,0,0,1,0]` означает, что в выборке из 12 объектов тестовой выборки аномалиями считаются первые три и предпоследний. Остальные считаются обычными.\n",
    "\n",
    "> ВНИМАНИЕ! Сопоставление при проверке будет производиться только по номерам объектов в тестовой выборке. Поэтому выборку при вычислении функции потерь не следует перемешивать. То есть, при создании загрузчика данных `torch.utils.data.DataLoader` аргумент перемешивания должен быть выключен: `shuffle=False`\n",
    "\n",
    "### Задание 8: примените обученную модель автокодировщика к данным тестовой выборки. Вычислите функцию потерь на каждом объекте тестовой выборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "test_dataset = DS(mnist_test_samples, val_transforms)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "loss_function = None\n",
    "\n",
    "losses = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    with tqdm(total=len(test_loader)) as pbar:\n",
    "        for data in test_loader:\n",
    "            ## здесь следует вычислить значения функции потерь для всех элементов тестовой выборки.\n",
    "            curr_loss = 0.0\n",
    "            ## YOUR CODE HERE\n",
    "            \n",
    "            losses.append(curr_loss)\n",
    "            pbar.update(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Анализ значений функции потерь\n",
    "Проанализируйте распределение значений функции потерь и найдите объекты, на которых она слишком большая.\n",
    "\n",
    "### Задание 9:\n",
    "- Отобразите гистограмму значений функции потерь. Сделайте выводы (напишите ТЕКСТ) относительно значений для обычных объектов и аномалий.\n",
    "- Найдите объекты-аномалии, отобразите их.\n",
    "- Вычислите на них обученный вами автокодировщик. Отобразите рядом объекты-аномалии и их реконструкцию, вычисленную вашим автокодировщиком."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 10: создайте файл маркировки аномалий\n",
    "\n",
    "В этом задании требуется записать в файл признаки аномальности для всех объектов тестовой выборки в том порядке, в котором эти объекты идут в выборке. Это должен быть просто текстовый файл. В нем не должно быть никаких заголовков, никаких дополнительных символов. Только `0` или `1`\n",
    "\n",
    "<br />\n",
    "пример содержимого файла (для выборки длиной 244 объекта, из которых 6 оказались помечены как аномалии):\n",
    "\n",
    "`0000000000000010000000000000000000000000000000000000000000000000000000100000000000000000000000000000000000000000100000000000000000000000000000000000000000000000000000000000000001000000000000000000000000000000000000000000000000000000001100000000`\n",
    "\n",
    "<br /><br />\n",
    "Финальным решением этого ДЗ является этот файл. Его нужно сдать вместе с ноутбуком с вашим кодом."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## YOUR CODE HERE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
